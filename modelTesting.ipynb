{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533730fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "from pathlib import Path\n",
    "import random\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import json\n",
    "\n",
    "import boto3\n",
    "\n",
    "\n",
    "path = Path(\"baseline.json\")\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "data = data[\"data\"]\n",
    "\n",
    "def detect_image_format(path: Path) -> str:\n",
    "    ext = path.suffix.lower().lstrip(\".\")\n",
    "    return \"jpeg\" if ext == \"jpg\" else ext\n",
    "\n",
    "def load_image_bytes(path: Path) -> bytes:\n",
    "    return path.read_bytes()\n",
    "\n",
    "def call_converse_once(client, model_id: str, prompt: str, image_bytes: bytes, image_format: str,) -> dict:\n",
    "\n",
    "\n",
    "    messages = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"text\": prompt},\n",
    "            {\"image\": {\"format\": image_format, \"source\": {\"bytes\": image_bytes}}},\n",
    "        ],\n",
    "    }]\n",
    "\n",
    "    resp = client.converse(\n",
    "        modelId=model_id,\n",
    "        messages=messages,\n",
    "    )\n",
    "\n",
    "    # Extract concatenated text blocks from the first output message.\n",
    "    content_blocks = resp.get(\"output\", {}).get(\"message\", {}).get(\"content\", []) or []\n",
    "    description = \"\".join(block.get(\"text\", \"\") for block in content_blocks if \"text\" in block).strip()\n",
    "\n",
    "    return {\"model_id\": model_id, \"text\": description, \"raw\": resp}\n",
    "\n",
    "def call_openai(client, model_id: str, prompt: str, image_path: Path, image_format: str,\n",
    "                max_tokens: int = 400, temperature: float = 0.2, top_p: float = 0.9) -> dict:\n",
    "\n",
    "    image = client.files.create(\n",
    "        file=open(image_path, \"rb\"),\n",
    "        purpose=\"user_data\"\n",
    "    )\n",
    "    messages = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \n",
    "        [\n",
    "            {\n",
    "                \"type\": \"input_image\",\n",
    "                \"file_id\": image.id\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"input_text\",\n",
    "                \"text\": prompt\n",
    "            }\n",
    "        ],\n",
    "    }]\n",
    "\n",
    "    resp = client.responses.create(\n",
    "        model=model_id,\n",
    "        input=messages,\n",
    "    )\n",
    "\n",
    "\n",
    "    return {\"model_id\": model_id, \"text\": resp.output_text, \"raw\": resp}\n",
    "\n",
    "def random_image_path(folder):\n",
    "    exts = {\".png\", \".jpg\", \".jpeg\", \".gif\", \".bmp\", \".tiff\", \".webp\"}\n",
    "    images = [p for p in Path(folder).iterdir() if p.suffix.lower() in exts]\n",
    "    return random.choice(images) if images else None\n",
    "\n",
    "def test_prompt(prompt, image_path):\n",
    "    model_ids = [\n",
    "        \"amazon.nova-pro-v1:0\",\n",
    "        \"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "        \"gpt-5\"\n",
    "    ]\n",
    "    image_format = detect_image_format(image_path)\n",
    "    image_bytes = load_image_bytes(image_path)\n",
    "    region = \"us-east-1\"\n",
    "    bedrock_client = boto3.client(\"bedrock-runtime\", region_name=region)\n",
    "    openai_client = OpenAI()\n",
    "\n",
    "    max_tokens = 8191\n",
    "\n",
    "    results = []\n",
    "    with ThreadPoolExecutor(max_workers=min(8, len(model_ids))) as pool:\n",
    "            futs = {\n",
    "                pool.submit(\n",
    "                    call_openai if m.startswith(\"gpt\") else call_converse_once,\n",
    "                    openai_client if m.startswith(\"gpt\") else bedrock_client,\n",
    "                    m, prompt, \n",
    "                    image_path if m.startswith(\"gpt\") else image_bytes,\n",
    "                    image_format\n",
    "                ): m for m in model_ids\n",
    "            }\n",
    "            for fut in as_completed(futs):\n",
    "                try:\n",
    "                    result = fut.result()\n",
    "                    if result[\"raw\"] and \"usage\" in result[\"raw\"]:\n",
    "                        result[\"totalTokens\"] = result[\"raw\"][\"usage\"].get(\"totalTokens\")\n",
    "\n",
    "                    elif result[\"raw\"].usage:\n",
    "                        result[\"totalTokens\"] = result[\"raw\"].usage.total_tokens\n",
    "                    else:\n",
    "                        result[\"totalTokens\"] = \"N/A\"\n",
    "                    results.append(result)\n",
    "                except Exception as e:\n",
    "                    results.append({\"model_id\": futs[fut], \"text\": f\"[ERROR] {type(e).__name__}: {e}\", \"raw\": None, \"totalTokens\": \"N/A\"})\n",
    "\n",
    "    from IPython.display import HTML, display\n",
    "    from pathlib import Path\n",
    "    import html\n",
    "\n",
    "\n",
    "    img_src = Path(image_path).as_posix()\n",
    "    image_file_name = Path(image_path).name\n",
    "    baseline_desc =[it for it in data[\"items\"]\n",
    "        if image_file_name.lower() in str(it.get(\"frameImageURL\")).lower()]\n",
    "    results.append({\n",
    "        \"model_id\": \"baseline\",\n",
    "        \"text\": baseline_desc,\n",
    "        \"totalTokens\": \"N/A\"\n",
    "    })\n",
    "\n",
    "    text = \"\\n\\n\".join(\n",
    "        f\"{r['model_id']}:\\n{r['text']}\\nTotal Tokens: {r['totalTokens']}\" for r in results\n",
    "    )\n",
    "    \n",
    "    safe_text = html.escape(text)\n",
    "\n",
    "    display(HTML(f\"\"\"\n",
    "    <div style=\"display:flex; gap:24px; align-items:flex-start; margin:8px 0;\">\n",
    "    <img src=\"{img_src}\"\n",
    "        style=\"max-width:50%; height:auto; object-fit:contain; border:1px solid #ddd; border-radius:8px;\"/>\n",
    "    <div style=\"flex:1; white-space:pre-wrap; word-wrap:break-word; font-family:ui-monospace, SFMono-Regular, Menlo, Consolas, 'Liberation Mono', monospace; font-size:14px; line-height:1.5;\">\n",
    "        {safe_text}\n",
    "    </div>\n",
    "    </div>\n",
    "    \"\"\"))\n",
    "\n",
    "image = random_image_path(\"pokemon-scenes-clips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac00dac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fcbd3a94-e4d3-44f6-963f-df58c0f1d333.jpg\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"display:flex; gap:24px; align-items:flex-start; margin:8px 0;\">\n",
       "    <img src=\"pokemon-scenes-clips/fcbd3a94-e4d3-44f6-963f-df58c0f1d333.jpg\"\n",
       "        style=\"max-width:50%; height:auto; object-fit:contain; border:1px solid #ddd; border-radius:8px;\"/>\n",
       "    <div style=\"flex:1; white-space:pre-wrap; word-wrap:break-word; font-family:ui-monospace, SFMono-Regular, Menlo, Consolas, 'Liberation Mono', monospace; font-size:14px; line-height:1.5;\">\n",
       "        amazon.nova-pro-v1:0:\n",
       "Action: The primary action in the frame is a man in a white lab coat, wearing a cap and green glasses, standing and appearing to speak or instruct. Another character, a boy in a blue and white striped shirt with a red cap, is leaning over a desk, seemingly engaged in an activity with a yellow Pokémon. Several other characters, both humans and Pokémon, are present in the background, some standing, some sitting, and some interacting with each other.\n",
       "\n",
       "Entities: The entities in the frame include various animated characters and Pokémon. The man in the white lab coat is the most prominent human figure. The boy in the blue and white striped shirt is another significant human character. Various Pokémon characters are present, including a yellow Pokémon on the desk, a blue blob-like Pokémon, and several others with distinct appearances. The desks are large, cylindrical, and green, and the setting appears to be an outdoor classroom or training area with a wooden floor and a backdrop of greenery.\n",
       "\n",
       "Environmental and Contextual Analysis: The setting is an outdoor classroom or training area, indicated by the desks, wooden floor, and open, airy environment with natural light. The presence of multiple characters and Pokémon suggests a learning or training context, possibly related to Pokémon training or education.\n",
       "\n",
       "Key Elements: The key elements in the frame include the man in the white lab coat, who appears to be an instructor or leader, the boy interacting with the yellow Pokémon, and the various Pokémon characters in the background. The desks and the outdoor classroom setting are also significant, providing context for the scene.\n",
       "\n",
       "Insights and Interpretations: The scene likely depicts a moment of instruction or training, with the man in the white lab coat leading the activity. The boy’s interaction with the yellow Pokémon suggests a hands-on learning experience. The diverse group of characters and Pokémon indicates a collaborative and engaging environment. The implications could be that this is part of a larger narrative involving Pokémon training or education, with potential future developments related to the characters’ interactions and growth.\n",
       "Total Tokens: 1756\n",
       "\n",
       "anthropic.claude-3-5-sonnet-20240620-v1:0:\n",
       "An animated scene depicts a classroom or lecture hall setting with various cartoon characters and creatures. In the foreground, a dark-skinned individual in a white lab coat and cap appears to be teaching or presenting. Behind them, several characters are seated in large, cylindrical desks. These characters include a mix of human-like figures and fantastical creatures, all with exaggerated expressions of surprise, shock, or excitement. Notable entities include a yellow mouse-like creature (Pikachu), a large green plant-like being, and various colorful humanoid characters. The background suggests an indoor environment with windows revealing greenery outside. The overall mood of the scene is one of commotion or unexpected revelation, with most characters displaying open mouths and wide eyes. This appears to be a scene from an animated series, likely related to the Pokémon franchise, given the presence of recognizable characters. The diverse cast and their reactions suggest a moment of high drama or surprise within the context of the story, possibly during a lesson or demonstration gone awry.\n",
       "Total Tokens: 1709\n",
       "\n",
       "gpt-5:\n",
       "Lively animated classroom scene with a sudden disturbance: about six humans—one adult male teacher at front left (mid‑step, arms thrown out, mouth open) and five teens at curved individual desks—all jerk backward or stare left with shocked expressions, some raising their hands defensively. Multiple Pokémon react simultaneously: a yellow mouse-like Pokémon (Pikachu) springs up from the center desk beside a boy in a blue striped shirt; a brown fox-like Pokémon (Eevee) stands alert on the right desk; a blue seal/clown-like Pokémon beside it flails in surprise; at the back a huge red, spiked turtle-like Pokémon rears behind a shirtless teen who throws his arms up; next to them a tall green/red plant-like Pokémon leans forward while a girl clutches a small white‑and‑green hedgehog-like creature; on the left a blonde girl hugs a small white fox-like Pokémon. Setting appears to be an indoor wooden classroom with curved desks, smooth plank flooring, and large bright windows suggesting daytime. Key elements: universal alarm on faces, defensive postures, and a mid-jump Pikachu, implying something unexpected is happening just off-frame to the left (e.g., loud impact, intruding creature, or attack). The class session has been abruptly interrupted; likely next actions include ducking, retreating, or preparing to confront the unseen cause.\n",
       "Total Tokens: 2836\n",
       "\n",
       "baseline:\n",
       "[]\n",
       "Total Tokens: N/A\n",
       "    </div>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"You are an AI model designed to perform in-depth analysis of a single frame extracted from a video stream.\n",
    "    The frame represents a clear image of a detected scene within the video. Your task is to analyze and describe the action, entities, and any relevant elements present in the image.\n",
    "    Instructions:\n",
    "    1. Identify and Describe the Action: \n",
    "    Determine if there is any action or movement occurring in the frame.\n",
    "    Provide a detailed description of the action, including the subjects involved (e.g., humans, animals, vehicles).\n",
    "    If multiple actions are occurring, describe each one separately.\n",
    "    \n",
    "    2. Identify and Describe Entities: \n",
    "    Identify all significant entities in the image, such as humans, animals, vehicles, or objects.\n",
    "    For humans: Provide details about their number, gender (if identifiable), age group, posture, and interaction with other entities.\n",
    "    For animals: Specify the type, number, and their behavior or interaction with the environment or other entities.\n",
    "    For objects: Identify any important objects, their positioning, and their possible relevance to the scene.\n",
    "    \n",
    "    3. Environmental and Contextual Analysis: \n",
    "    Analyze the environment depicted in the frame, including the setting (e.g., indoor, outdoor, urban, rural).\n",
    "    Note any specific environmental conditions such as weather, lighting, or time of day that might impact the scene.\n",
    "    Consider the context of the action or entities—what might have led to this scene or what could happen next.\n",
    "    \n",
    "    4. Identify and Highlight Key Elements: \n",
    "    Point out any elements in the image that are crucial to understanding the scene, such as facial expressions, gestures, specific objects, or environmental details.\n",
    "    Highlight any anomalies or unusual aspects in the frame.\n",
    "    \n",
    "    5. Provide Insights and Interpretations: \n",
    "    Offer potential interpretations of the scene, considering the interactions between entities and the context provided by the environment.\n",
    "    Suggest any implications or consequences of the depicted action or scene, especially if they are important for further analysis or decision-making.\n",
    "    \n",
    "    6. General Guidelines: \n",
    "    Be as specific and detailed as possible in your descriptions.\n",
    "    Avoid making assumptions beyond what can be directly inferred from the image.\n",
    "    Focus on clarity and relevance, ensuring that your analysis is directly tied to the visual elements in the frame.\n",
    "    Limit the number of returned tokens of the description to 8191 tokens.\n",
    "    Directly describe the scene without any introductory phrases or explanations, like \"in the image\" or \"the scene shows.\"\n",
    "    \n",
    "    Provide the results as a single paragraph for the overall information required by the instructions.\n",
    "    Do not start the description with \"in the image\" or \"the image shows\" or \"the scene depicts\", or any other similar variants as it is already implied that you are describing the scene from the image.\n",
    "    If the scene image does not contain any discernible features, object or entities visible, do not provide the description at all, just the rest of the information!\n",
    "    The analysis will be used to understand the scene within the context of the video stream, potentially aiding in real-time decision-making or further processing of the video content.\"\"\"\n",
    "\n",
    "test_prompt(prompt,image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f77cb788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fcbd3a94-e4d3-44f6-963f-df58c0f1d333.jpg\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"display:flex; gap:24px; align-items:flex-start; margin:8px 0;\">\n",
       "    <img src=\"pokemon-scenes-clips/fcbd3a94-e4d3-44f6-963f-df58c0f1d333.jpg\"\n",
       "        style=\"max-width:50%; height:auto; object-fit:contain; border:1px solid #ddd; border-radius:8px;\"/>\n",
       "    <div style=\"flex:1; white-space:pre-wrap; word-wrap:break-word; font-family:ui-monospace, SFMono-Regular, Menlo, Consolas, 'Liberation Mono', monospace; font-size:14px; line-height:1.5;\">\n",
       "        amazon.nova-pro-v1:0:\n",
       "In a lively classroom setting, a diverse group of anime characters, including both humans and Pokémon, are gathered around individual desks. A male character in a white lab coat and cap stands at the front, appearing to be giving a lecture or presentation. Other characters are seated at their desks, showing a range of expressions from interest to boredom. The environment is bright and colorful, with wooden floors and large windows letting in natural light.\n",
       "Total Tokens: 955\n",
       "\n",
       "anthropic.claude-3-5-sonnet-20240620-v1:0:\n",
       "[ERROR] ThrottlingException: An error occurred (ThrottlingException) when calling the Converse operation (reached max retries: 4): Too many requests, please wait before trying again.\n",
       "Total Tokens: N/A\n",
       "\n",
       "gpt-5:\n",
       "A lively Pokémon School classroom erupts in surprise as everyone reacts at once: Ash Ketchum jumps back with Pikachu, Professor Kukui flinches at the front, and Lillie clutches her Alolan Vulpix while gasping. Mallow hugs a Shaymin beside her Tsareena, Kiawe throws his arms up with Turtonator looming behind him, and Lana looks alarmed while an Azumarill and her Eevee brace on her desk; the Rotom Dex hovers nearby with a worried expression. The students sit at curved wooden desks in a bright room with large windows looking out to greenery, giving the commotion a sudden, chaotic energy.\n",
       "Total Tokens: 1507\n",
       "\n",
       "baseline:\n",
       "[]\n",
       "Total Tokens: N/A\n",
       "    </div>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"You are an AI model designed to perform in-depth analysis of a single frame extracted from a video stream.\n",
    "    The frame represents a clear image of a detected scene within the video. Your task is to analyze and describe the action, entities, and any relevant elements present in the image.\n",
    "    Instructions:\n",
    "    1. Provide a single paragraph summary that encapsulates the overall scene, including key actions, entities, and environmental context.\n",
    "    2. Be specific with the names of any characters you recognize. If you do not recognize any characters say nothing on the subject \n",
    "    3. use simple but descriptive language\n",
    "    4. Directly describe the scene without any introductory phrases or explanations, like \"in the image\" or \"the scene shows.\"\"\"\n",
    "test_prompt(prompt,image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cc9919",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
